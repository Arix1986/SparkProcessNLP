{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ›  **Upload Librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.ml.linalg import SparseVector, DenseVector\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import when, lit\n",
    "from app_spark_processor import *\n",
    "from app_text_pprocessor import *\n",
    "from app_hyperparams import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš€ **Inicio del Entrenamiento del Modelo** ðŸŽ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()\n",
    "processor = SparkNLPProcessor(spark_session=spark)\n",
    "spark = processor.get_session()\n",
    "datasete = DatasetLoader(spark)\n",
    "test = datasete.load_csv('/datasets/train_dataset.csv')\n",
    "df_filtered = test.filter(col(\"sentiment\").isin([0, 1]))\n",
    "df_=TextCleaner(spark, use_lemma=True, use_stop_words=True,expand_contractions=True).clean_dataframe(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_dense(vec):\n",
    "    if isinstance(vec, SparseVector):\n",
    "        return vec.toArray().tolist() \n",
    "    elif isinstance(vec, DenseVector):\n",
    "        return list(vec) \n",
    "    return [0.0] * 5000 \n",
    "\n",
    "vector_to_dense_udf = udf(vector_to_dense, ArrayType(FloatType()))\n",
    "df_dense = df_.withColumn(\"tfidf_dense\", vector_to_dense_udf(col(\"tfidf_features\")))\n",
    "tfidf_numpy = np.vstack(\n",
    "    df_dense.select(\"tfidf_dense\").rdd.mapPartitions(\n",
    "        lambda rows: (np.array(row[\"tfidf_dense\"], dtype=np.float32) for row in rows)\n",
    "    ).collect()\n",
    ")\n",
    "np.save(\"./embeddings/tfidf_features.npy\", tfidf_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_numpy = np.vstack(\n",
    "            df_.select(\"bert_embeddings\").rdd.mapPartitions(\n",
    "                lambda rows: [np.array(row[\"bert_embeddings\"][0].embeddings) for row in rows]\n",
    "            ).collect()\n",
    "        )\n",
    "np.save(\"./embeddings/bert_numpy.npy\", bert_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_.withColumn(\"sentiment\", when(df_.sentiment.cast(\"int\").isNull(), lit(-1)).otherwise(df_.sentiment.cast(\"int\")))\n",
    "labels = np.array(\n",
    "    df_.select(\"sentiment\").rdd.flatMap(lambda x: x).collect()\n",
    ").astype(np.int64)\n",
    "np.save(\"./embeddings/labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“‚ **Cargar los embeddings si existen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_numpy = np.load(\"/content/drive/MyDrive/NeoNexus/bert_numpy.npy\")\n",
    "tfidf_numpy = np.load(\"/content/drive/MyDrive/NeoNexus/tfidf_features.npy\")\n",
    "labels = np.load(\"/content/drive/MyDrive/NeoNexus/labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bert_numpy.shape)\n",
    "print(tfidf_numpy.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study=HyperparameterOptimization(bert_numpy=bert_numpy,tfidf_numpy=tfidf_numpy, labels=labels)\n",
    "study.optimize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
